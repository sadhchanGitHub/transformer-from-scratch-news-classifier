{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebbe19f2-e259-4729-8478-376996702ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All necessary libraries and modules imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Core PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# TorchText for NLP\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "\n",
    "# Standard Python Libraries (Only if needed, math is in model.py)\n",
    "# import math \n",
    "\n",
    "# custom modules\n",
    "import sys\n",
    "import os\n",
    "# Go up one level from 'notebooks' to the project root\n",
    "sys.path.append(os.path.abspath('..')) \n",
    "\n",
    "\n",
    "from model import TransformerClassifier\n",
    "from utils import evaluate\n",
    "import config\n",
    "\n",
    "\n",
    "\n",
    "print(\"✅ All necessary libraries and modules imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "339195d1-12d1-4624-8dc1-0c4280e2d6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vocab loaded. Size: 95812 words.\n",
      "✅ Tokenizer defined. Running on device: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- Part 1: Load Saved Artifacts ---\n",
    "\n",
    "# Define the category mapping globally\n",
    "CATEGORY_MAP = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n",
    "\n",
    "# Define global components\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "# Load the vocabulary\n",
    "vocab = torch.load(config.VOCAB_SAVE_PATH)\n",
    "PAD_IDX = vocab['<pad>'] # Not needed for single-sentence predict, but good practice\n",
    "\n",
    "print(f\"✅ Vocab loaded. Size: {len(vocab)} words.\")\n",
    "print(f\"✅ Tokenizer defined. Running on device: {config.DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bdea7eb-d8fb-4bfb-b9c5-b23f4b46824b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model architecture created and trained weights loaded from ../models/transformer_news_classifier_best.pth.\n"
     ]
    }
   ],
   "source": [
    "# --- Part 2: Load Trained Model ---\n",
    "\n",
    "# DEFINE THE EXACT SAME HYPERPARAMETERS USED FOR TRAINING\n",
    "VOCAB_SIZE = len(vocab)\n",
    "\n",
    "# Instantiate the model architecture\n",
    "inference_model = TransformerClassifier(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    d_model=config.D_MODEL,\n",
    "    num_heads=config.NUM_HEADS,\n",
    "    num_layers=config.NUM_LAYERS,\n",
    "    d_ff=config.D_FF,\n",
    "    num_classes=config.NUM_CLASSES\n",
    ").to(config.DEVICE)\n",
    "\n",
    "# Load the saved weights from your BEST model file\n",
    "inference_model.load_state_dict(torch.load(config.MODEL_SAVE_PATH))\n",
    "\n",
    "# Set the model to evaluation mode (CRITICAL)\n",
    "inference_model.eval()\n",
    "\n",
    "print(f\"✅ Model architecture created and trained weights loaded from {config.MODEL_SAVE_PATH}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "344b8110-f4ba-4127-b932-2030710d8c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(text, model, vocab, tokenizer, device):\n",
    "    \"\"\"\n",
    "    Takes a raw text string and returns the predicted category.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input news article or sentence.\n",
    "        model (nn.Module): Your trained TransformerClassifier.\n",
    "        vocab (Vocab): The vocabulary object from your training data.\n",
    "        tokenizer (callable): The tokenizer you used for training.\n",
    "        device (str): The device the model is on ('cuda' or 'cpu').\n",
    "        \n",
    "    Returns:\n",
    "        str: The predicted category name.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # 2. Tokenize and Numericalize the text\n",
    "    # We use the same vocab and tokenizer as in training\n",
    "    token_ids = torch.tensor([vocab[token] for token in tokenizer(text)], dtype=torch.long)\n",
    "    \n",
    "    # 3. Add the batch dimension and move to the correct device\n",
    "    # The model expects a batch of data, so we unsqueeze to create a batch of 1\n",
    "    token_ids = token_ids.unsqueeze(0).to(device)\n",
    "    \n",
    "    # 4. Get the model's prediction (logits)\n",
    "    # No gradient tracking is needed\n",
    "    with torch.no_grad():\n",
    "        logits = model(token_ids)\n",
    "    \n",
    "    # 5. Get the predicted class index by finding the max logit\n",
    "    predicted_index = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # 6. Convert the index back to a human-readable category name\n",
    "    # The AG_NEWS categories are: 1-World, 2-Sports, 3-Business, 4-Sci/Tech\n",
    "    # Since we subtracted 1, our indices are: 0-World, 1-Sports, 2-Business, 3-Sci/Tech\n",
    "    category_map = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n",
    "    \n",
    "    return CATEGORY_MAP[predicted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef2bc15f-99e5-4a2b-bdf9-debc2d74c590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: 'The US economy is a puzzle but the pieces aren't fitting together'\n",
      "Predicted Category: Sports\n",
      "\n",
      "Article: 'Premier League: Chelsea held by Crystal Palace & Forest beat Brentford - reaction'\n",
      "Predicted Category: World\n",
      "\n",
      "Article: 'Will AI make language dubbing easy for film and TV?'\n",
      "Predicted Category: Sci/Tech\n",
      "\n",
      "Article: 'Putin agreed to security guarantees for Ukraine being part of potential peace deal, US envoy says'\n",
      "Predicted Category: World\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- INFERENCE TEST ---\n",
    "\n",
    "\n",
    "\n",
    "# Example 1: A Business/Finance news headline\n",
    "news_article_1 = \"The US economy is a puzzle but the pieces aren't fitting together\"\n",
    "prediction_1 = predict(news_article_1, inference_model, vocab, tokenizer, config.DEVICE)\n",
    "print(f\"Article: '{news_article_1}'\")\n",
    "print(f\"Predicted Category: {prediction_1}\\n\")\n",
    "\n",
    "\n",
    "# Example 2: A Sports news headline\n",
    "news_article_2 = \"Premier League: Chelsea held by Crystal Palace & Forest beat Brentford - reaction\"\n",
    "prediction_2 = predict(news_article_2, inference_model, vocab, tokenizer, config.DEVICE)\n",
    "print(f\"Article: '{news_article_2}'\")\n",
    "print(f\"Predicted Category: {prediction_2}\\n\")\n",
    "\n",
    "\n",
    "# Example 3: A Sci/Tech news headline\n",
    "news_article_3 = \"Will AI make language dubbing easy for film and TV?\"\n",
    "prediction_3 = predict(news_article_3, inference_model, vocab, tokenizer, config.DEVICE)\n",
    "print(f\"Article: '{news_article_3}'\")\n",
    "print(f\"Predicted Category: {prediction_3}\\n\")\n",
    "\n",
    "# Example 4: A World news headline\n",
    "news_article_4 = \"Putin agreed to security guarantees for Ukraine being part of potential peace deal, US envoy says\"\n",
    "prediction_4 = predict(news_article_4, inference_model, vocab, tokenizer, config.DEVICE)\n",
    "print(f\"Article: '{news_article_4}'\")\n",
    "print(f\"Predicted Category: {prediction_4}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476d72b0-85dd-4264-9cc1-f21abf43d25c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_news",
   "language": "python",
   "name": "transformer_news"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
