{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-markdown",
   "metadata": {},
   "source": [
    "# Transformer News Classifier: Training Notebook\n",
    "\n",
    "This notebook demonstrates the training process for the Transformer-based news classifier. It leverages the custom `transformer_news` Python package, which contains all the necessary functions for data processing, model definition, and training.\n",
    "\n",
    "**Note:** Before running, ensure you have installed the package in editable mode from the project's root directory:\n",
    "```bash\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledgments-markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments:\n",
    "The core concepts and architectural patterns implemented here were learned from and inspired by several excellent educational resources, including Jay Alammar's \"The Illustrated Transformer\", Andrej Karpathy's \"Let's build GPT\", and Josh Starmer's course on DeepLearning.AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-markdown",
   "metadata": {},
   "source": [
    "### 1. Imports\n",
    "\n",
    "First, we import all necessary libraries. Most importantly, we import the `train` module from our own `transformer_news` package, which contains the main training orchestration logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 13:29:16,612 - Starting training run...\n"
     ]
    }
   ],
   "source": [
    "# Standard Libraries\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Import the main training function from our package\n",
    "from transformer_news import train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logging-markdown",
   "metadata": {},
   "source": [
    "### 2. Setup Logging\n",
    "\n",
    "We'll configure the logging system to print messages directly to the notebook's output. This allows us to see the progress from the training functions inside our package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "logging-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    # Force logging to be sent to the notebook's stdout\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-markdown",
   "metadata": {},
   "source": [
    "### 3. Set Training Parameters\n",
    "\n",
    "Here, we define the parameters for this specific training run. This is the only place you need to make changes to experiment with different settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "config-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to False to use the full AG_NEWS dataset (takes longer)\n",
    "USE_SAMPLE_DATASET = True\n",
    "\n",
    "# Number of training epochs\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# The size of the sample to use if USE_SAMPLE_DATASET is True\n",
    "SAMPLE_SIZE = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "execution-markdown",
   "metadata": {},
   "source": [
    "### 4. Run Training\n",
    "\n",
    "With everything set up, we can now start the training process with a single call to `train.main()`. This function, located in `src/transformer_news/train.py`, will handle everything: loading data, creating the model, and executing the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "execution-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 13:29:16,685 - Loading SAMPLE of 2000...\n",
      "2025-08-19 13:29:16,868 - ✅ Vocab saved to /home/hyd_in_zrh/projects/personal_projects/transformer-from-scratch-news-classifier/transformer-from-scratch-news-classifier/models/newsclassification_vocab.pth\n",
      "2025-08-19 13:29:16,869 - ✅ Train and Test DataLoaders created successfully.\n",
      "2025-08-19 13:29:16,869 - --- Inspecting the first batch from the DataLoader ---\n",
      "2025-08-19 13:29:16,875 - Batch token shape: torch.Size([64, 119])\n",
      "2025-08-19 13:29:16,876 - Batch label shape: torch.Size([64])\n",
      "2025-08-19 13:29:16,876 - Unique labels in this batch: tensor([0, 1, 2, 3])\n",
      "2025-08-19 13:29:16,877 - Labels range: 0–3\n",
      "2025-08-19 13:29:16,877 - ✅ Labels are correct.\n",
      "2025-08-19 13:29:18,465 - ✅ Model, optimizer, and loss function defined.\n",
      "2025-08-19 13:29:22,481 - Epoch 01/5 | Train Loss: 1.3428 | Test Accuracy: 0.3020\n",
      "2025-08-19 13:29:22,565 -   -> New best model saved with accuracy: 0.3020\n",
      "2025-08-19 13:29:24,767 - Epoch 02/5 | Train Loss: 1.2080 | Test Accuracy: 0.4235\n",
      "2025-08-19 13:29:24,818 -   -> New best model saved with accuracy: 0.4235\n",
      "2025-08-19 13:29:26,985 - Epoch 03/5 | Train Loss: 0.9731 | Test Accuracy: 0.5420\n",
      "2025-08-19 13:29:27,040 -   -> New best model saved with accuracy: 0.5420\n",
      "2025-08-19 13:29:29,221 - Epoch 04/5 | Train Loss: 0.7826 | Test Accuracy: 0.5445\n",
      "2025-08-19 13:29:30,592 -   -> New best model saved with accuracy: 0.5445\n",
      "2025-08-19 13:29:32,875 - Epoch 05/5 | Train Loss: 0.6774 | Test Accuracy: 0.5890\n",
      "2025-08-19 13:29:32,936 -   -> New best model saved with accuracy: 0.5890\n"
     ]
    }
   ],
   "source": [
    "train.main(\n",
    "    full_dataset=(not USE_SAMPLE_DATASET),\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    sample_size=SAMPLE_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "**Training complete!** The best model has been saved to the `models/` directory, and the vocabulary is stored as `newsclassification_vocab.pth`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_news",
   "language": "python",
   "name": "transformer_news"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
